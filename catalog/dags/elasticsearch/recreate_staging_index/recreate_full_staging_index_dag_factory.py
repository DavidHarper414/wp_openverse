"""
# Recreate Full Staging Index DAG factory

This module creates the full staging index recreation DAGs for each media type
using a factory function.

Staging index creation is handled by the _staging_ ingestion server. The DAGs
generated by the factory function in this module trigger the ingestion server
`REINDEX` action to create a new index in the staging elasticsearch cluster
for the given media type, suffixed by the current timestamp. The DAG awaits
the completion of the index creation and then points the given `target_alias`
alias to the newly created index. If the `target_alias` previously pointed to
another index and the `delete_old_index` param is enabled, the index which
was replaced will be deleted.

## When this DAG runs

This DAG is on a `None` schedule and is run manually.

## Race conditions

Because this DAG runs on the staging ingestion server and staging elasticsearch
cluster, it does _not_ interfere with the `data_refresh` or
`create_filtered_index` DAGs.
"""
from datetime import datetime, timedelta

from airflow import DAG
from airflow.decorators import task
from airflow.models.param import Param
from airflow.utils.task_group import TaskGroup
from airflow.utils.trigger_rule import TriggerRule

from common import ingestion_server, slack
from common.constants import (
    DAG_DEFAULT_ARGS,
    MEDIA_TYPES,
    XCOM_PULL_TEMPLATE,
    MediaType,
)
from data_refresh.data_refresh_types import DATA_REFRESH_CONFIGS


def recreate_full_staging_index_dag_factory(media_type: MediaType):
    dag_id = f"recreate_full_{media_type}_staging_index"

    def create_index(index_suffix: str) -> TaskGroup:
        """Create the new elasticsearch index on the staging cluster."""

        # Get the DataRefresh config associated with this media type, in order to get
        # the reindexing timeout information.
        config = next(
            conf for conf in DATA_REFRESH_CONFIGS if conf.media_type == media_type
        )

        with TaskGroup(group_id="create_index") as create_index_group:
            ingestion_server.trigger_and_wait_for_task(
                action="REINDEX",
                model=media_type,
                data={"index_suffix": new_index_suffix},
                timeout=config.data_refresh_timeout,
                http_conn_id="staging_data_refresh",
            )
            return create_index_group

    def point_alias(target_alias: str, index_suffix: str) -> TaskGroup:
        """
        Alias the index with the given suffix to the target_alias, first removing the
        target_alias from any other indices to which it is linked.
        """
        point_alias_payload = {
            "alias": target_alias,
            "index_suffix": index_suffix,
        }

        with TaskGroup(group_id="point_alias") as point_alias_group:
            ingestion_server.trigger_and_wait_for_task(
                action="POINT_ALIAS",
                model=media_type,
                data=point_alias_payload,
                timeout=timedelta(hours=12),  # matches the ingestion server's wait time
                http_conn_id="staging_data_refresh",
            )
        return point_alias_group

    with DAG(
        dag_id=dag_id,
        default_args=DAG_DEFAULT_ARGS,
        schedule=None,
        start_date=datetime(2023, 4, 1),
        tags=["database"],
        max_active_runs=1,
        catchup=False,
        doc_md=__doc__,
        params={
            "target_alias": Param(
                default=f"{media_type}-full",
                type="string",
                description=("The target alias for the newly created index."),
            ),
            "delete_old_index": Param(
                default=False,
                type="boolean",
                description=(
                    "Whether to delete the index previously pointed to be the "
                    "`target_alias`, if it is replaced. The index will "
                    "only be deleted if the alias was successfully linked to the "
                    " newly created index."
                ),
            ),
        },
        render_template_as_native_obj=True,
    ) as dag:

        @task.branch
        def should_delete_index(should_delete: bool, old_index: str):
            if should_delete and old_index:
                # We should try to delete the old index only if the param is enabled,
                # and we were able to find an index with the traget_alias in the
                # preceding task.
                return "trigger_delete_index"
            # Skip straight to notifying Slack.
            return "notify_complete"

        # Suffix the index with a current timestamp.
        new_index_suffix = ingestion_server.generate_index_suffix.override(
            trigger_rule=TriggerRule.NONE_FAILED
        )("full-{{ ts_nodash.lower() }}")

        # Get the index currently aliased by the target_alias, in case it must be
        # deleted later.
        get_current_index_if_exists = ingestion_server.get_current_index(
            "{{ params.target_alias }}", http_conn_id="staging_data_refresh"
        )

        # Create the new Elasticsearch index
        do_create_index = create_index(new_index_suffix)

        # Actually point the alias
        do_point_alias = point_alias(
            target_alias="{{ params.target_alias }}", index_suffix=new_index_suffix
        )

        check_if_should_delete_index = should_delete_index(
            should_delete="{{ params.delete_old_index }}",
            old_index=XCOM_PULL_TEMPLATE.format(
                get_current_index_if_exists.task_id, "return_value"
            ),
        )

        # Branch only reached if check_if_should_delete_index is True.
        # Deletes the old index pointed to by the target_alias after the alias has been
        # unlinked.
        delete_old_index = ingestion_server.trigger_task(
            action="DELETE_INDEX",
            model=media_type,
            data={
                "index_suffix": XCOM_PULL_TEMPLATE.format(
                    get_current_index_if_exists.task_id, "return_value"
                ),
            },
            http_conn_id="staging_data_refresh",
        )

        notify_complete = slack.notify_slack.override(
            task_id="notify_complete", trigger_rule=TriggerRule.NONE_FAILED
        )(
            text=(
                "Finished creating full staging index"
                f" `{media_type}-{new_index_suffix}` aliased to"
                " `{{ params.target_alias }}`."
            ),
            username=f"{media_type.capitalize()} Staging Index Creation",
            dag_id=dag_id,
        )

        # Set up dependencies
        get_current_index_if_exists >> new_index_suffix
        new_index_suffix >> do_create_index >> do_point_alias
        do_point_alias >> check_if_should_delete_index
        check_if_should_delete_index >> [delete_old_index, notify_complete]
        delete_old_index >> notify_complete

    return dag


for media_type in MEDIA_TYPES:
    recreate_full_staging_index_dag_factory(media_type)
